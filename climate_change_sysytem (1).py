# -*- coding: utf-8 -*-
"""climate change sysytem

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lZ8DgP_gZLGJCkwzbpjVRiuWxYsQm3mJ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/climate_nasa.csv')

df

df.head()

df.info()

df.columns

df.describe()

df.duplicated()

df = df.drop_duplicates()

df.duplicated()

df.isnull().sum()

df.columns

#identify missing value

# Visualize missing values
plt.figure(figsize=(12, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

plt.figure(figsize=(12, 6))
sns.barplot(df.isnull().sum())
plt.title('Missing Values Heatmap')
plt.show()

# Count of missing values per column
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100
missing_df = pd.DataFrame({
    'Missing Values': missing_values,
    'Percentage': missing_percentage
})
print(missing_df)

numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
for col in numerical_cols:
    if df[col].isnull().sum() > 0:
        df[col].fillna(df[col].median(), inplace=True)  # You can use mean() instead of median()
        print(f'Filled missing values in {col} with median.')

categorical_cols = df.select_dtypes(include=['object', 'category']).columns
for col in categorical_cols:
    if df[col].isnull().sum() > 0:
        df[col].fillna(df[col].mode()[0], inplace=True)  # You can use a placeholder like 'Unknown'
        print(f'Filled missing values in {col} with mode.')

# Check for missing values in each column
missing_values = df.isnull().sum()

# Calculate the percentage of missing data in each column
missing_percentage = (missing_values / len(df)) * 100

# Combine missing counts and percentages into a DataFrame
missing_data = pd.DataFrame({
    'Missing Values': missing_values,
    'Percentage': missing_percentage
})

# Display columns that have missing data
missing_data[missing_data['Missing Values'] > 0]

# Drop rows with any missing values (this might be too aggressive)
df_cleaned = df.dropna()

# Drop columns with missing values (only if the column is not important)
df_cleaned = df.dropna(axis=1)

print(df.dtypes)

# Convert 'date_column' to datetime if applicable
if 'date_column' in df.columns:
    df['date_column'] = pd.to_datetime(df['date_column'], errors='coerce')
    print('Converted date_column to datetime.')

# Convert object columns with limited unique values to category
for col in categorical_cols:
    if df[col].nunique() < 50:  # Threshold can be adjusted
        df[col] = df[col].astype('category')
        print(f'Converted {col} to category type.')

# Example: Handling errors during datetime conversion
if 'date_column' in df.columns:
    df['date_column'] = pd.to_datetime(df['date_column'], errors='coerce')
    # Check for any conversion failures
    if df['date_column'].isnull().sum() > 0:
        print('Some dates could not be converted and are set as NaT.')

# Check for duplicate rows
duplicates = df.duplicated()

# Display duplicate rows if any
df[duplicates]

# Remove duplicate rows
df.drop_duplicates(inplace=True)

# Confirm that duplicates were removed
df.duplicated().sum()  # This should return 0

# Check for duplicate rows
duplicates = df.duplicated()
print(f'Total duplicate rows: {duplicates.sum()}')

# Remove duplicate rows
df.drop_duplicates(inplace=True)
print('Duplicate rows removed.')

# Verify that duplicates are removed
print(f'Total duplicate rows after removal: {df.duplicated().sum()}')

for col in numerical_cols:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

#Detecting Outliers Using Z-Score



from scipy import stats

# Calculate Z-scores
z_scores = np.abs(stats.zscore(df[numerical_cols].dropna()))
# Define a threshold
threshold = 3
# Identify outliers
outliers = (z_scores > threshold).any(axis=1)
print(f'Number of outlier rows: {outliers.sum()}')

# Remove outliers
df = df[~outliers]
print('Outliers removed based on Z-score threshold.')

#Cap/Floor Outliers (Winsorization)
from scipy.stats.mstats import winsorize

for col in numerical_cols:
    df[col] = winsorize(df[col], limits=[0.05, 0.05])  # Caps at 5th and 95th percentiles
    print(f'Applied winsorization to {col}.')

# Visualize boxplots again to ensure outliers are handled
for col in numerical_cols:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col} After Handling Outliers')
    plt.show()

# Example: Renaming columns to lowercase and replacing spaces with underscores
df.rename(columns=lambda x: x.strip().lower().replace(' ', '_'), inplace=True)
print('Columns renamed to lowercase with underscores.')
print(df.columns)

df.info()

df.describe()

df.head()

df.columns